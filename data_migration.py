"""
Script Di chuy·ªÉn D·ªØ li·ªáu - Airbnb WebApp
C√¥ng c·ª• di chuy·ªÉn d·ªØ li·ªáu an to√†n t·ª´ SQLite sang PostgreSQL
Bao g·ªìm backup, validation v√† rollback procedures
"""

import json
import logging
import os
import sqlite3
import sys
from datetime import datetime
from typing import Dict, List

from sqlalchemy import create_engine, text
from sqlmodel import Session

# Th√™m ƒë∆∞·ªùng d·∫´n ƒë·ªÉ import models
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from models import (Booking, Building, Channel, ExpenseCategory, ExtraCharge,
                    ImportLog, Property, User, UserSession)

# C·∫•u h√¨nh logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler('migration.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class DatabaseMigrator:
    """C√¥ng c·ª• di chuy·ªÉn database v·ªõi c√°c t√≠nh nƒÉng an to√†n"""
    
    def __init__(self, source_db: str, target_db: str):
        """
        Kh·ªüi t·∫°o migrator
        
        Args:
            source_db: ƒê∆∞·ªùng d·∫´n database ngu·ªìn (SQLite)
            target_db: Connection string database ƒë√≠ch (PostgreSQL)
        """
        self.source_db = source_db
        self.target_db = target_db
        self.backup_dir = "backups"
        self.migration_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # T·∫°o th∆∞ m·ª•c backup
        os.makedirs(self.backup_dir, exist_ok=True)
        
        logger.info("üöÄ Kh·ªüi t·∫°o Database Migrator")
        logger.info(f"üìÇ Source: {source_db}")
        logger.info(f"üéØ Target: {target_db.split('@')[0]}@***")  # ·∫®n password
    
    def create_backup(self) -> str:
        """T·∫°o backup database ngu·ªìn"""
        try:
            backup_file = os.path.join(
                self.backup_dir, 
                f"backup_sqlite_{self.migration_timestamp}.db"
            )
            
            logger.info("üìã ƒêang t·∫°o backup database ngu·ªìn...")
            
            # Copy SQLite database
            import shutil
            shutil.copy2(self.source_db, backup_file)
            
            logger.info(f"‚úÖ Backup ƒë√£ t·∫°o: {backup_file}")
            return backup_file
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói t·∫°o backup: {e}")
            raise e
    
    def export_data_to_json(self) -> Dict[str, List[Dict]]:
        """Xu·∫•t t·∫•t c·∫£ d·ªØ li·ªáu t·ª´ SQLite sang JSON format"""
        try:
            logger.info("üì§ ƒêang xu·∫•t d·ªØ li·ªáu t·ª´ SQLite...")
            
            # K·∫øt n·ªëi SQLite
            conn = sqlite3.connect(self.source_db)
            conn.row_factory = sqlite3.Row  # ƒê·ªÉ c√≥ th·ªÉ access by column name
            
            exported_data = {}
            
            # Danh s√°ch tables c·∫ßn xu·∫•t
            tables = [
                'building', 'property', 'channel', 'booking', 
                'importlog', 'user', 'usersession', 'extracharge', 
                'expensecategory'
            ]
            
            for table in tables:
                try:
                    cursor = conn.execute(f"SELECT * FROM {table}")
                    rows = cursor.fetchall()
                    
                    # Convert sang list of dict
                    data = []
                    for row in rows:
                        row_dict = dict(row)
                        # Convert datetime strings n·∫øu c·∫ßn
                        for key, value in row_dict.items():
                            if isinstance(value, str) and ('created_at' in key or 'updated_at' in key or 'date' in key):
                                try:
                                    # Validate datetime format
                                    datetime.fromisoformat(value.replace('Z', '+00:00'))
                                except:
                                    pass  # Gi·ªØ nguy√™n n·∫øu kh√¥ng ph·∫£i datetime
                        data.append(row_dict)
                    
                    exported_data[table] = data
                    logger.info(f"‚úÖ Xu·∫•t table '{table}': {len(data)} records")
                    
                except sqlite3.OperationalError as e:
                    if "no such table" in str(e).lower():
                        logger.warning(f"‚ö†Ô∏è Table '{table}' kh√¥ng t·ªìn t·∫°i, b·ªè qua")
                        exported_data[table] = []
                    else:
                        raise e
            
            conn.close()
            
            # L∆∞u exported data ra file
            export_file = os.path.join(
                self.backup_dir,
                f"exported_data_{self.migration_timestamp}.json"
            )
            
            with open(export_file, 'w', encoding='utf-8') as f:
                json.dump(exported_data, f, ensure_ascii=False, indent=2, default=str)
            
            logger.info(f"üíæ D·ªØ li·ªáu ƒë√£ xu·∫•t ra: {export_file}")
            return exported_data
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói xu·∫•t d·ªØ li·ªáu: {e}")
            raise e
    
    def validate_data(self, data: Dict[str, List[Dict]]) -> bool:
        """Validate d·ªØ li·ªáu tr∆∞·ªõc khi import"""
        try:
            logger.info("üîç ƒêang validate d·ªØ li·ªáu...")
            
            validation_results = []
            
            # Ki·ªÉm tra tables quan tr·ªçng
            required_tables = ['building', 'property', 'channel']
            for table in required_tables:
                if table not in data or len(data[table]) == 0:
                    validation_results.append(f"‚ùå Table '{table}' thi·∫øu d·ªØ li·ªáu")
                else:
                    validation_results.append(f"‚úÖ Table '{table}': {len(data[table])} records")
            
            # Ki·ªÉm tra t√≠nh to√†n v·∫πn d·ªØ li·ªáu
            if 'booking' in data and 'property' in data:
                property_ids = {p['id'] for p in data['property']}
                booking_property_ids = {b['property_id'] for b in data['booking'] if b.get('property_id')}
                
                missing_properties = booking_property_ids - property_ids
                if missing_properties:
                    validation_results.append(f"‚ö†Ô∏è Bookings c√≥ property_id kh√¥ng t·ªìn t·∫°i: {missing_properties}")
                else:
                    validation_results.append("‚úÖ T√≠nh to√†n v·∫πn booking-property OK")
            
            # In k·∫øt qu·∫£ validation
            for result in validation_results:
                logger.info(result)
            
            # Ki·ªÉm tra c√≥ l·ªói critical kh√¥ng
            has_critical_errors = any("‚ùå" in result for result in validation_results)
            
            if has_critical_errors:
                logger.error("‚ùå Validation th·∫•t b·∫°i - c√≥ l·ªói critical")
                return False
            else:
                logger.info("‚úÖ Validation th√†nh c√¥ng")
                return True
                
        except Exception as e:
            logger.error(f"‚ùå L·ªói validation: {e}")
            return False
    
    def import_data_to_postgresql(self, data: Dict[str, List[Dict]]) -> bool:
        """Import d·ªØ li·ªáu v√†o PostgreSQL"""
        try:
            logger.info("üì• ƒêang import d·ªØ li·ªáu v√†o PostgreSQL...")
            
            # T·∫°o engine PostgreSQL
            target_engine = create_engine(self.target_db)
            
            # Mapping table names to SQLModel classes
            model_mapping = {
                'building': Building,
                'property': Property,
                'channel': Channel,
                'booking': Booking,
                'importlog': ImportLog,
                'user': User,
                'usersession': UserSession,
                'extracharge': ExtraCharge,
                'expensecategory': ExpenseCategory
            }
            
            with Session(target_engine) as session:
                # T·∫°o tables
                from sqlmodel import SQLModel
                SQLModel.metadata.create_all(target_engine)
                logger.info("‚úÖ Database schema ƒë√£ t·∫°o")
                
                # Import theo th·ª© t·ª± (ƒë·ªÉ tr√°nh foreign key issues)
                import_order = [
                    'building', 'channel', 'expensecategory', 
                    'property', 'user', 'booking', 'extracharge',
                    'importlog', 'usersession'
                ]
                
                total_imported = 0
                
                for table_name in import_order:
                    if table_name in data and table_name in model_mapping:
                        model_class = model_mapping[table_name]
                        table_data = data[table_name]
                        
                        if not table_data:
                            logger.info(f"‚è≠Ô∏è Table '{table_name}' tr·ªëng, b·ªè qua")
                            continue
                        
                        logger.info(f"üì• Import table '{table_name}': {len(table_data)} records...")
                        
                        imported_count = 0
                        for record in table_data:
                            try:
                                # T·∫°o instance model
                                instance = model_class(**record)
                                session.add(instance)
                                imported_count += 1
                                
                                # Commit theo batch ƒë·ªÉ tr√°nh memory issues
                                if imported_count % 100 == 0:
                                    session.commit()
                                    
                            except Exception as e:
                                logger.warning(f"‚ö†Ô∏è L·ªói import record trong {table_name}: {e}")
                                session.rollback()
                                continue
                        
                        # Final commit cho table
                        session.commit()
                        total_imported += imported_count
                        logger.info(f"‚úÖ Imported {imported_count} records v√†o '{table_name}'")
                
                logger.info(f"üéâ Import ho√†n t·∫•t! T·ªïng c·ªông: {total_imported} records")
                return True
                
        except Exception as e:
            logger.error(f"‚ùå L·ªói import d·ªØ li·ªáu: {e}")
            return False
    
    def verify_migration(self) -> bool:
        """Verify migration b·∫±ng c√°ch so s√°nh record counts"""
        try:
            logger.info("üîç ƒêang verify migration...")
            
            # K·∫øt n·ªëi c·∫£ 2 databases
            source_engine = create_engine(f"sqlite:///{self.source_db}")
            target_engine = create_engine(self.target_db)
            
            tables_to_check = [
                'building', 'property', 'channel', 'booking', 
                'user', 'extracharge', 'expensecategory'
            ]
            
            verification_passed = True
            
            with Session(source_engine) as source_session, Session(target_engine) as target_session:
                for table in tables_to_check:
                    try:
                        # Count trong source
                        source_count = source_session.execute(
                            text(f"SELECT COUNT(*) FROM {table}")
                        ).scalar()
                        
                        # Count trong target
                        target_count = target_session.execute(
                            text(f"SELECT COUNT(*) FROM {table}")
                        ).scalar()
                        
                        if source_count == target_count:
                            logger.info(f"‚úÖ Table '{table}': {source_count} = {target_count}")
                        else:
                            logger.error(f"‚ùå Table '{table}': Source={source_count} != Target={target_count}")
                            verification_passed = False
                            
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ verify table '{table}': {e}")
            
            if verification_passed:
                logger.info("üéâ Migration verification PASSED!")
            else:
                logger.error("‚ùå Migration verification FAILED!")
            
            return verification_passed
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói verify migration: {e}")
            return False
    
    def run_migration(self) -> bool:
        """Ch·∫°y to√†n b·ªô qu√° tr√¨nh migration"""
        try:
            logger.info("üöÄ B·∫ÆT ƒê·∫¶U MIGRATION DATABASE")
            logger.info("=" * 50)
            
            # B∆∞·ªõc 1: T·∫°o backup
            backup_file = self.create_backup()
            
            # B∆∞·ªõc 2: Xu·∫•t d·ªØ li·ªáu
            exported_data = self.export_data_to_json()
            
            # B∆∞·ªõc 3: Validate d·ªØ li·ªáu
            if not self.validate_data(exported_data):
                logger.error("‚ùå Validation th·∫•t b·∫°i - d·ª´ng migration")
                return False
            
            # B∆∞·ªõc 4: Import v√†o PostgreSQL
            if not self.import_data_to_postgresql(exported_data):
                logger.error("‚ùå Import th·∫•t b·∫°i - rollback required")
                return False
            
            # B∆∞·ªõc 5: Verify migration
            if not self.verify_migration():
                logger.error("‚ùå Verification th·∫•t b·∫°i - ki·ªÉm tra d·ªØ li·ªáu")
                return False
            
            logger.info("=" * 50)
            logger.info("üéâ MIGRATION TH√ÄNH C√îNG!")
            logger.info(f"üìã Backup t·∫°i: {backup_file}")
            logger.info("üìä Log t·∫°i: migration.log")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Migration th·∫•t b·∫°i: {e}")
            return False

def main():
    """H√†m main ƒë·ªÉ ch·∫°y migration"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Migration Database Airbnb WebApp")
    parser.add_argument("--source", default="app.db", help="SQLite database file")
    parser.add_argument("--target", required=True, help="PostgreSQL connection string")
    parser.add_argument("--dry-run", action="store_true", help="Ch·ªâ validate, kh√¥ng import")
    
    args = parser.parse_args()
    
    # Ki·ªÉm tra file source t·ªìn t·∫°i
    if not os.path.exists(args.source):
        logger.error(f"‚ùå File database ngu·ªìn kh√¥ng t·ªìn t·∫°i: {args.source}")
        return False
    
    # T·∫°o migrator
    migrator = DatabaseMigrator(args.source, args.target)
    
    if args.dry_run:
        logger.info("üß™ DRY RUN MODE - ch·ªâ validate d·ªØ li·ªáu")
        exported_data = migrator.export_data_to_json()
        return migrator.validate_data(exported_data)
    else:
        return migrator.run_migration()

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)